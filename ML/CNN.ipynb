{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "61b2d2b1-0fb5-4e1b-89e8-a49fa3aaaba6",
   "metadata": {},
   "source": [
    "# Convolutional Neural Networks\n",
    "Convolutional Neural Network (CNN) is a type of Deep Learning neural network architecture commonly used in Computer Vision. Computer vision is a field of Artificial Intelligence that enables a computer to understand and interpret the image or visual data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84bf952-9453-4b89-8b3f-f8f1d0700d31",
   "metadata": {},
   "source": [
    "## Convolution operation\n",
    "We first take our inut image and cross multiply each nxn block with the nxn feature detector\n",
    "to get the feature map\n",
    "The feature map helps us preserve only the important features of the image while eliminating the unessecary details of the image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9551dcd2-d1b9-4bfe-b93e-bf51b6184091",
   "metadata": {},
   "source": [
    "## ReLu Layer\n",
    "After applying feature detector to an image we get black which isnegative and white which is positive values\n",
    "the rectifier or relu Layer removes all the negative values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa79f74-bc19-4907-abe4-d4c208ffe132",
   "metadata": {},
   "source": [
    "## Pooling\n",
    "After applying the feature map and relu layer There are times where the features of the image may have different orientation and be distorted at times.To encompass this we use pooling.\n",
    "We take a box of nxn pixels and we find the maximum value in that box and disregard the others.This is only for max pooling there are other types too like mean sum etc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a535e2-7e7f-419b-9b6b-8be760054465",
   "metadata": {},
   "source": [
    "## Flatenning\n",
    "Converting the 2d matricx of features into a 1d array for input into the neural network\n",
    "\n",
    "In CNN we have fully connected hidden layers which means every input node is connected to every output node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7318d3c9-b770-4528-8297-e62d64c9322c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2f506b69-005b-46e0-be65-6c881fee94bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.13.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "561b3b5a-4cec-4e3c-863b-2d23a63add81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip  =True\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'training_set',\n",
    "    target_size =(64,64),\n",
    "    batch_size = 32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255,)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'test_set',\n",
    "    target_size =(64,64),\n",
    "    batch_size = 32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06d05112-8c72-4860-a83b-abd60425e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn  =tf.keras.models.Sequential()\n",
    "# adding convolutional layers\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu',input_shape=[64,64,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c820e021-25c2-435a-855a-c310cde4ddf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58743169-dd5f-4ca8-acc0-9948e2b55c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding another layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "afb5cd52-0dea-45b8-83a1-443d4fa58c25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a07b963-121b-49ec-9c9f-25c719a2cf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fully connected layer\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))\n",
    "#Output layer\n",
    "cnn.add(tf.keras.layers.Dense(units=1,activation='sigmoid'))\n",
    "#Optimizer\n",
    "cnn.compile(optimizer = 'adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "339bb2dc-2423-4701-b843-dce8152bb006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 208s 801ms/step - loss: 0.6741 - accuracy: 0.5890 - val_loss: 0.7044 - val_accuracy: 0.5440\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 185s 742ms/step - loss: 0.6025 - accuracy: 0.6744 - val_loss: 0.5651 - val_accuracy: 0.7055\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 132s 528ms/step - loss: 0.5763 - accuracy: 0.6948 - val_loss: 0.5369 - val_accuracy: 0.7300\n",
      "Epoch 4/10\n",
      "191/250 [=====================>........] - ETA: 28s - loss: 0.5440 - accuracy: 0.7245"
     ]
    }
   ],
   "source": [
    "# training the data\n",
    "cnn.fit(x = train_generator,validation_data = test_generator,epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde0da08-4fff-41d2-b6b6-055460a57015",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ae9fc0-cde0-418b-b188-9062feb6b9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "test_image = image.load_img('dog.jpg',target_size=(64,64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image =np.expand_dims(test_image,axis=0)\n",
    "result = cnn.predict(test_image)\n",
    "if(result == 0):\n",
    "    print(\"It is cat\")\n",
    "else:\n",
    "    print(\"It is a dog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dea1d4-97a8-4423-8aea-4c139d19472e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
