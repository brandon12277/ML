{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ada8627a-dc78-4aff-a630-8e01dbbc99ec",
   "metadata": {},
   "source": [
    "# Steps in Data preprocessing\n",
    "1. import the data\n",
    "2. clean the data\n",
    "3. spilt data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed066bd-cfae-4660-a99c-0d889e19e371",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dfefc745-9fc5-49c1-ab60-a335309936e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef10afa-353d-4e35-abf0-fa0b8bdc4919",
   "metadata": {},
   "source": [
    "# Reading the Data From dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c13858a7-7897-4d81-bed9-5ff16543fb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Country   Age   Salary Purchased\n",
      "0   France  44.0  72000.0        No\n",
      "1    Spain  27.0  48000.0       Yes\n",
      "2  Germany  30.0  54000.0        No\n",
      "3    Spain  38.0  61000.0        No\n",
      "4  Germany  40.0      NaN       Yes\n",
      "5   France  35.0  58000.0       Yes\n",
      "6    Spain   NaN  52000.0        No\n",
      "7   France  48.0  79000.0       Yes\n",
      "8  Germany  50.0  83000.0        No\n",
      "9   France  37.0  67000.0       Yes\n"
     ]
    }
   ],
   "source": [
    "data =pd.read_csv(\"Data.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a6e2b2-7c88-43db-80e4-5b940bae7a29",
   "metadata": {},
   "source": [
    "In a Dataset we have two features and dependent variable vectors\n",
    "1. Features are the column which are used to predict the dependent variables or the output.They are also called indepnedent variables who predict the dependent variables Ex: in above Age and salary\n",
    "2. Dependent variables are what is predicted or the output. Ex purchased"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce3789-e91e-4952-ba59-050bfe81abfb",
   "metadata": {},
   "source": [
    "# Taking the two entities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84d25766-6de9-4151-82ff-a8d775f56d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['France' 44.0 72000.0]\n",
      " ['Spain' 27.0 48000.0]\n",
      " ['Germany' 30.0 54000.0]\n",
      " ['Spain' 38.0 61000.0]\n",
      " ['Germany' 40.0 nan]\n",
      " ['France' 35.0 58000.0]\n",
      " ['Spain' nan 52000.0]\n",
      " ['France' 48.0 79000.0]\n",
      " ['Germany' 50.0 83000.0]\n",
      " ['France' 37.0 67000.0]]\n",
      "['No' 'Yes' 'No' 'No' 'Yes' 'Yes' 'No' 'Yes' 'No' 'Yes']\n"
     ]
    }
   ],
   "source": [
    "X = data.iloc[:,:3].values #iloc is location of indexes first set is row second is column\n",
    "Y=data.iloc[:,3].values\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b0c12a-6e39-4c76-a809-5d84942939e6",
   "metadata": {},
   "source": [
    "# Taking care of missing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f3d980-2513-4517-8517-ec85fe64d586",
   "metadata": {},
   "source": [
    "We have missing data in germany 40.0 so lets take care of that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4466ad3-81c1-4605-957c-51374799a9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.24.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480acdc8-46c3-4232-9c32-6b991a25372e",
   "metadata": {},
   "source": [
    "# Imputer\n",
    "this is what is used to fill and take care of missing data\n",
    "here the missing_values represent what kind of evalue to fill in this case nan and the strategy is mean of values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a500ba82-67ea-447b-b478-7b0af40de24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 nan]\n",
      " [35.0 58000.0]\n",
      " [nan 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n",
      "\n",
      " [[44.0 72000.0]\n",
      " [27.0 48000.0]\n",
      " [30.0 54000.0]\n",
      " [38.0 61000.0]\n",
      " [40.0 63777.77777777778]\n",
      " [35.0 58000.0]\n",
      " [38.77777777777778 52000.0]\n",
      " [48.0 79000.0]\n",
      " [50.0 83000.0]\n",
      " [37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "print(X[:,1:]) # old\n",
    "imputer.fit(X[:,1:])\n",
    "X[:,1:]=imputer.transform(X[:,1:])\n",
    "print(\"\\n\",X[:,1:]) # new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d789a9-47f1-494c-960a-cfba40aeff22",
   "metadata": {},
   "source": [
    "# Encoding The Categorical data\n",
    "the dataset contains numerical data -age and salary\n",
    "categorical data - country and Y\n",
    "\n",
    "thus this needs to be converted into numerical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66da97d9-1f4a-404a-a225-8fc6e120f1a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0 0.0 0.0 44.0 72000.0]\n",
      " [0.0 0.0 1.0 27.0 48000.0]\n",
      " [0.0 1.0 0.0 30.0 54000.0]\n",
      " [0.0 0.0 1.0 38.0 61000.0]\n",
      " [0.0 1.0 0.0 40.0 63777.77777777778]\n",
      " [1.0 0.0 0.0 35.0 58000.0]\n",
      " [0.0 0.0 1.0 38.77777777777778 52000.0]\n",
      " [1.0 0.0 0.0 48.0 79000.0]\n",
      " [0.0 1.0 0.0 50.0 83000.0]\n",
      " [1.0 0.0 0.0 37.0 67000.0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder=\"passthrough\")\n",
    "X=np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da032f79-540b-4242-9c92-2cfd270ffd63",
   "metadata": {},
   "source": [
    "# Difference between OnehotEncoding and LabelEncoding\n",
    "LabelEncoding - converts data into labels depending on the number of data for ex if there is Yes and No output it will have 0 and 1 thus\n",
    "it establishes a specific relation between rows\n",
    "\n",
    "OneHotEncoding -  converts a specific column into n seprate columns depending on the the number of values these columns will have specifically values \n",
    "0 and 1 depending on the data being used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56f05cf2-95ac-4bbe-b774-108355e85220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(),[0])],remainder=\"passthrough\")\n",
    "X=np.array(ct.fit_transform(X))\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434d0887-6220-4d43-8e7f-ee5ab8efc03b",
   "metadata": {},
   "source": [
    "# Splitting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a06dc9d-5127-4bc5-b1f4-0de19d49c0fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 1 0 1] [0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2,random_state=1)\n",
    "print(Y_train,Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7df0bd-ec62-4b4b-8d4d-4ac7a949396c",
   "metadata": {},
   "source": [
    "# Feature Scaling\n",
    "It is done so that some features do not dominate other features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b8f9671-34c2-4001-b785-ae86d2755226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.0 0.0 1.0 -0.19159184384578545 -1.0781259408412425]\n",
      " [0.0 1.0 0.0 -0.014117293757057777 -0.07013167641635372]\n",
      " [1.0 0.0 0.0 0.566708506533324 0.633562432710455]\n",
      " [0.0 0.0 1.0 -0.30453019390224867 -0.30786617274297867]\n",
      " [0.0 0.0 1.0 -1.9018011447007988 -1.420463615551582]\n",
      " [1.0 0.0 0.0 1.1475343068237058 1.232653363453549]\n",
      " [0.0 1.0 0.0 1.4379472069688968 1.5749910381638885]\n",
      " [1.0 0.0 0.0 -0.7401495441200351 -0.5646194287757332]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "X_train[:,3:]=sc.fit_transform(X_train[:,3:])\n",
    "X_test[:,3:]=sc.fit_transform(X_test[:,3:])\n",
    "\n",
    "print(X_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
