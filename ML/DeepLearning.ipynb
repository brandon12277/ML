{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bc91cf1-905d-4313-97b8-da3bd812ed6d",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "It is a branch of machine learning that deals with mimicing the human brain by building an artificial nueral network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a41dcbb-0b14-4f00-9b6d-bb63a95c10f3",
   "metadata": {},
   "source": [
    "## Artificial Neural Network\n",
    "It is the technique of mimicing the human brain by building layers containing nodes called neurons and a artificial structure with these neurons\n",
    "to recreate the human brain\n",
    "\n",
    "### Neuron\n",
    "It is the smallest unit of the brain.<br>\n",
    "In ANN a every nueron has an input signal and an output signal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2d80fc-b552-4a6d-9d63-05c1abd0930d",
   "metadata": {},
   "source": [
    "## Activation function\n",
    "To pass the value to the ouptu variable we find the sum of the product of the weights and the input variables\n",
    "and pass the value to a function called activation function\n",
    "\n",
    "Types: <br>\n",
    "1. Threshold function : theta(x)  = { 1 :x>=0 or 0 if x<0 }\n",
    "2. Sigmoid function  : theta(x) = 1/(1+e^-x)\n",
    "3. Rectifier : theta(x) = max(x,0)\n",
    "4. Hyperbolic tangent : theta(x) = (1 - e^-2x)/(1 + e^-2x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c6fa0-8906-4d85-8f1c-a863299a1e88",
   "metadata": {},
   "source": [
    "## How does ANN learn from data\n",
    "The input variable is taken and passed along with wieghts to the activation function\n",
    "The function then calculates Y^\n",
    "The cost functions is calculated using C = (1/2 *(Y^-Y)^2)\n",
    "This value is sent back using backpropagation and the value of weights are adjusted \n",
    "this process is continued till we minimize the cost function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8d6469-e105-401c-a059-bffe90a4d1c6",
   "metadata": {},
   "source": [
    "## Gradient desecent\n",
    "It is basically the process of minimizing the cost function.\n",
    "It differentiaties the cost function at every point and find the slope of the point with the respect to the line of desecent\n",
    "Based on this data it moves its way to the point of minima\n",
    "\n",
    "## Stochastic descent\n",
    "Instead of finding the global minima it finds the local minimum\n",
    "It is faster than batch gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a9ed9-c162-432d-99fa-9f12f93a363d",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "The adjustment of weights after the cost function is calculated is called backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07b07044-99f5-41d8-9e39-4275e96ab946",
   "metadata": {},
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
